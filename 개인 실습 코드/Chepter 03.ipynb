{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chepter 03. 분류(Classification) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist DataSets ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as_frame 속성을 True로 주게 되면 pd.DataFrame로 반환,  \n",
    "as_frame 속성을 False로 주게 되면 np.ndarray로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist datasets 속성 분석 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets key\n",
    "\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python dic type의 datasets에서 key 값을 통해 value 호출 후 파악, 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train datasets's main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target == label, y_value (쉽게 말해서, 지도학습의 정답 값)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pixel1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pixel2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pixel3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pixel4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pixel5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  pixel1\n",
       "1  pixel2\n",
       "2  pixel3\n",
       "3  pixel4\n",
       "4  pixel5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnist['feature_names']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 sample에 대한 feature_names는 각 pixel 이름   \n",
    "28 by 28 size Matrix == n(feature) = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 DataSets의 설명, 요약, 철학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '554',\n",
       " 'name': 'mnist_784',\n",
       " 'version': '1',\n",
       " 'description_version': '1',\n",
       " 'format': 'ARFF',\n",
       " 'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
       " 'upload_date': '2014-09-29T03:28:38',\n",
       " 'language': 'English',\n",
       " 'licence': 'Public',\n",
       " 'url': 'https://www.openml.org/data/v1/download/52667/mnist_784.arff',\n",
       " 'file_id': '52667',\n",
       " 'default_target_attribute': 'class',\n",
       " 'tag': ['AzurePilot',\n",
       "  'OpenML-CC18',\n",
       "  'OpenML100',\n",
       "  'study_1',\n",
       "  'study_123',\n",
       "  'study_41',\n",
       "  'study_99',\n",
       "  'vision'],\n",
       " 'visibility': 'public',\n",
       " 'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
       " 'status': 'active',\n",
       " 'processing_date': '2020-11-20 20:12:09',\n",
       " 'md5_checksum': '0298d579eb1b86163de7723944c7e495'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['details']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAtaSets 의 상세정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN data Features  \n",
    "Features == pixel value 이기 때문에 따로 categories 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 key 값에 대한 value check  \n",
    "여기서 main feature를 X_value로, label을 y_value로 사용  \n",
    "```python\n",
    "main_feaure == minst['data'], label == mnist['target']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSets 구성 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 column 추출 설정\n",
    "X, y = mnist['data'], mnist['target'] # X 를 data column, y 를 target column을 끌어와서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist dataset의 원본은 (28, 28, 1) GrayScale 2D Matrix이지만, 여기서 주어진 dataset은 Flatten 처리 되어있음.\n",
    "\n",
    "원본 Mnist datasets 참고 url : https://www.tensorflow.org/datasets/catalog/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_sample = X[0].reshape(28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(visual_sample, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28 by 28 grayscale binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y data value의 data type이 문자형으로 표시되어있음  \n",
    "대부분의 머신러닝 알고리즘은 숫자형 Data Type을 기대하기 때문에 TypeCast 진행  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y TypeCast\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from char type to (unsigned int(8bit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet Split ###  \n",
    "dataset을 Train data, valid(test) data로 분리  \n",
    "검증 과정 전까지 valid data는 건드리지 않는다.  \n",
    "  \n",
    "Chepter 02에서 housing price dataset에서, 일반적인 train_valid 비율인 8:2로 Split했지만,  \n",
    "Mnist dataset에서는 train:valid = 60000:10000 비율로 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류기(Classifier) 훈련 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진 분류기 (Binary Classifier) ###\n",
    "각 smaple에 대해 숫자 '5'인지 아닌지 판단하는 이진 분류기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # train data에서 label 값이 5인 경우만 추출\n",
    "y_test_5 = (y_test == 5) # test data에서 label 값이 5인 경우만 추출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 확률적 경사하강법 (Stochastic gradient descent) #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "sgd_clf.predict([visual_sample.reshape(784,)]) # Visualization을 진행했던 사진을 5로 예측했는지에 대한 물음 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 측정을 위해 교차 검증(Cross Validation) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation 3회(Subset 3개)  \n",
    "Scoring = 정확도 기준으로 평가  \n",
    "  \n",
    "결과는 모두 95%에 가깝게 나왔기 때문에 성능이 매우 좋은 모델로 평가될 수도 있음  \n",
    "더 정확한 결과를 알아보기위해 더미를 생성 후 넣어보고 결과를 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 더미 생성 후 모델 평가 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator # 기본 추정기 생성 모델\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더미 체킹을 진행해도 ACC 90%이상으로 나옴  \n",
    "총 labels가 10개, 그 중에서 '5'에 해당하는 10%를 제외한 모든 samples에 대해 False값을 반환 받기 때문에  \n",
    "더미 체킹 과정에서 모두 다 False로 예측한다면, '5' label을 가진 sample을 제외한 다른 값들에 대해서 올바른 예측이 되어버림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오차 행렬(Confusion Matrix) ####  \n",
    "각 Class(label)별 예측 결과를 정리해둔 행렬  \n",
    "행은 실제 클래스를, 열은 예측된 클래스를 가리킴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측 음성</th>\n",
       "      <th>예측 양성</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>실제 음성</th>\n",
       "      <td>실제 음성, 예측 음성(TN)</td>\n",
       "      <td>실제 음성, 예측 양성(FP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>실제 양성</th>\n",
       "      <td>실제 양성, 예측 음성(FN)</td>\n",
       "      <td>실제 양성, 예측 양성(TP)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  예측 음성             예측 양성\n",
       "실제 음성  실제 음성, 예측 음성(TN)  실제 음성, 예측 양성(FP)\n",
       "실제 양성  실제 양성, 예측 음성(FN)  실제 양성, 예측 양성(TP)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차행렬 pandas 를 통해 구현\n",
    "Confusion_Matrix_ex = pd.DataFrame([[\"실제 음성, 예측 음성(TN)\", \"실제 음성, 예측 양성(FP)\"],\n",
    "                                    [\"실제 양성, 예측 음성(FN)\", \"실제 양성, 예측 양성(TP)\"]], index=['실제 음성', '실제 양성'], columns=['예측 음성', '예측 양성'])\n",
    "\n",
    "\n",
    "Confusion_Matrix_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 분석을 위해 예측값 필요\n",
    "from sklearn.model_selection import cross_val_predict # cross_val_score 처럼 교차검증을 하는데 리턴 값이 점수가 아닌 예측값임\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn 함수를 이용해서 실제 오차 행렬 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 5가 아닌 값을 5가 아니라고 판단된 n(sample) == 53892    \n",
    "\n",
    "                             .  \n",
    "                             .  \n",
    "                             .  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도(Precision) ####\n",
    "오차행렬에서 뽑은 정보를 가지고 요약이 필요한 경우가 있다.  \n",
    "양성으로 예측한 수 대비 진양성 비율을 정밀도라고 한다.(양성 예측의 정확도)  \n",
    "  \n",
    "Precision = TP/TP+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 재현율(Recall) ####  \n",
    "  \n",
    "양성 샘플에 대한 정확도,  \n",
    "민감도(Sensitivity), 참 양성 비율(True postive rate)  \n",
    "  \n",
    "Recall = TP/TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 점수 (F1-Score) ####\n",
    "  \n",
    "정밀도와 재현율의 조화평균으로, 두 지표의 모든 특징을 반영할 수 있음  \n",
    "정밀도와 재현율이 비슷하면 F1-Score는 높게 나타나지만, 그러다고 마냥 좋다고 볼 수는 없는 지표이다.  \n",
    "EX) 유튜브 키즈 알고리즘 (P.136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도, 재현율의 상관관계 ####\n",
    "\n",
    "정밀도와 재현율은 경향성 방면에서 서로 트레이드오프 관계로, 각 모델별로 적절히 조율해서 사용하는게 베스트  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도와 재현율의 트레이드오프 관계 예시  \n",
    "\n",
    "![img][Ex-prec-recall traidoff](..\\img\\Ex-prec-recall traidoff.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결정함수(Decision Function)와 결정 임계값(Decision Threshold) ####  \n",
    "  \n",
    "결정 임계값을 정하는 결정함수의 역할에 따라 Positive Class와 Negative Class를 결정하는 기준이 바뀐다.  \n",
    "Code Block [13]에서 시각화에 사용했던 sample인 visual_sample의 점수를 확인하고 그것을 기준으로 임계값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_sample = visual_sample.reshape(784,).copy() # Visualization에 사용했던 Sample에 대해서 2D -> 1D로 Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sklearn의 함수들은 2D 미만의 np.ndarray를 기대하기 때문에 Flatten 시켜주지않으면 코드가 작동하지 않음*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deicsion Function with Threshold\n",
    "y_scores = sgd_clf.decision_function([visual_sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2164.22030239])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 Decision Threshold를 0으로 준다면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0\n",
    "y_visual_sample_pred = (y_scores > threshold) # 임계값보다 yscores가 크기때문에 True 반환\n",
    "\n",
    "y_visual_sample_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Threshold를 y_scores보다 크게 준다면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 8000\n",
    "y_visual_sample_pred = (y_scores > threshold) # 임계값보다 yscores가 작기때문에 False 반환\n",
    "\n",
    "y_visual_sample_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRC(Pricision-Recall Curve) ###  \n",
    "  \n",
    "PRC를 그리기 위해서 모든 y 값에 대한 예측값을 가져와야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_curve 함수는 3개의 return값을 반환한다. 이를 바탕으로 PRC를 그릴 수 있다.\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRC 시각화 (코드 복사해서 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정밀도 재현률 곡선 (PRC)\n",
    "\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "\n",
    "# recall 이 x축, precision이 y축\n",
    "# 오른쪽 위쪽에 붙어있을수록 좋은 모델\n",
    "# recall이 80정도에 precision이 급격히 줄어든다 : 적절한 위치의 임계값\n",
    "# 커브아래의 면적이 크면 좋은 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약, 정밀도 90%의 달성이 목표인 분류기를 만든다면, 정밀도가 90%인 지점의 Threshold 값을 찾아야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3370.0194991439557"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "\n",
    "threshold_90_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Precision에서의 recall_score 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores > threshold_90_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞선 코드와 반대로, threshold를 이용한 Precision 구하기 (여기서는 검산의 역할)\n",
    "precision_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47980077476480354"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Classifier는 Precision 0.90 에서 Recall 0.47..을 가지는 Classifier 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaded5a7997c05586ebf7af8dfcd805bc79ec256ab8efddbe3d03cb2ab32050e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mljnu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
